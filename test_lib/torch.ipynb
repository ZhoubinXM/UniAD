{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = torch.nn.Embedding(10, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-1.9576e-01,  9.0685e-01, -2.3725e-01],\n",
       "        [-6.5495e-01, -4.4356e-01, -5.6937e-01],\n",
       "        [-7.6300e-01,  7.8565e-01, -1.1423e-01],\n",
       "        [ 1.6167e+00,  5.8848e-01, -9.2545e-01],\n",
       "        [-4.5452e-01,  1.7633e+00, -5.0979e-01],\n",
       "        [-1.7944e+00, -1.3099e+00, -2.6892e-01],\n",
       "        [ 4.7739e-01,  2.1953e-01, -7.2605e-01],\n",
       "        [-6.8092e-02, -5.1862e-01,  9.6706e-01],\n",
       "        [-3.5239e-04,  1.7474e+00,  5.9033e-01],\n",
       "        [-1.1159e-02, -1.5465e+00,  4.9035e-01]], requires_grad=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "put = torch.LongTensor([[1,2,4,5],[4,3,2,9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6550, -0.4436, -0.5694],\n",
       "         [-0.7630,  0.7856, -0.1142],\n",
       "         [-0.4545,  1.7633, -0.5098],\n",
       "         [-1.7944, -1.3099, -0.2689]],\n",
       "\n",
       "        [[-0.4545,  1.7633, -0.5098],\n",
       "         [ 1.6167,  0.5885, -0.9254],\n",
       "         [-0.7630,  0.7856, -0.1142],\n",
       "         [-0.0112, -1.5465,  0.4903]]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer(put)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "full() received an invalid combination of arguments - got (tuple, int, device=module, dtype=torch.dtype), but expected one of:\n * (tuple of ints size, Number fill_value, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, Number fill_value, *, tuple of names names, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[39m.\u001b[39;49mfull(\n\u001b[1;32m      2\u001b[0m             (\u001b[39mlen\u001b[39;49m(put),), \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mlong, device\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mcuda\n\u001b[1;32m      3\u001b[0m         )\n",
      "\u001b[0;31mTypeError\u001b[0m: full() received an invalid combination of arguments - got (tuple, int, device=module, dtype=torch.dtype), but expected one of:\n * (tuple of ints size, Number fill_value, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, Number fill_value, *, tuple of names names, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n"
     ]
    }
   ],
   "source": [
    "torch.full(\n",
    "            (len(put),), -1, dtype=torch.long, device=torch.cuda\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "卷积神经网络 学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([[0, 1, 2], [3,4,5], [6, 7, 8]])\n",
    "K = torch.tensor([[0,1],[2,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19., 25.],\n",
       "        [37., 43.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calcorr(X, K):\n",
    "    Y = torch.zeros((X.shape[0] - K.shape[0] + 1, X.shape[1] - K.shape[1] + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j] = (X[i:i+K.shape[0], j:j+K.shape[1]] * K).sum() # 无\n",
    "    return Y\n",
    "calcorr(X, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.ones((6, 8))\n",
    "X[:, 2:6] = 0\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = torch.tensor([[1.0, -1.0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcorr(X, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"位置编码\"\"\"\n",
    "    def __init__(self, num_hiddens, dropout, max_len=1000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # 创建一个足够长的P\n",
    "        self.P = torch.zeros((1, max_len, num_hiddens))\n",
    "        X = torch.arange(max_len, dtype=torch.float32).reshape(\n",
    "            -1, 1) / torch.pow(10000, torch.arange(\n",
    "            0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)\n",
    "        self.P[:, :, 0::2] = torch.sin(X)\n",
    "        self.P[:, :, 1::2] = torch.cos(X)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X + self.P[:, :X.shape[1], :].to(X.device)\n",
    "        return self.dropout(X)\n",
    "\n",
    "pos_encoding = PositionalEncoding(512, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uniad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "549d4bc81ae57afb7965088e353b61b9dd1bc5086e16f0efaf01a7389c04c744"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
